{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design model using class\n",
    "\"\"\"\n",
    "our model class should be inherit from nn.Module, which is base class for all neural network modules.\n",
    "member methods __init__() and forward() have to be implemented\n",
    "class nn.linear contain two member Tensors: weight and bias\n",
    "class nn.Linear has implemented the magic method __call__(),which enable the instance of the class can\n",
    "be called just like a function.Normally the forward() will be called \n",
    "\"\"\"\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # (1,1)是指输入x和输出y的特征维度，这里数据集中的x和y的特征都是1维的\n",
    "        # 该线性层需要学习的参数是w和b  获取w/b的方式分别是~linear.weight/linear.bias\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearModel(\n  (linear): Linear(in_features=1, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel()  # 这里的model是可调用的callable\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion = nn.MSELoss(reduction = \"sum\")  # reduction = \"mean\" 或者 reduction = \"sum\"\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 85.8578872680664\n1 38.222232818603516\n2 17.01618003845215\n3 7.575840473175049\n4 3.3732588291168213\n5 1.5023776292800903\n6 0.6695044636726379\n7 0.2987239956855774\n8 0.1336526721715927\n9 0.06015845388174057\n10 0.027431145310401917\n11 0.012852635234594345\n12 0.006353480275720358\n13 0.0034510772675275803\n14 0.0021501160226762295\n15 0.0015621514758095145\n16 0.0012916976120322943\n17 0.0011627344647422433\n18 0.0010968721471726894\n19 0.0010592305334284902\n20 0.0010342717869207263\n21 0.0010150682646781206\n22 0.0009985477663576603\n23 0.0009833343792706728\n24 0.0009688236168585718\n25 0.0009547306108288467\n26 0.000940923229791224\n27 0.0009273776668123901\n28 0.0009140370530076325\n29 0.0009008988854475319\n30 0.0008879458764567971\n31 0.0008751840214245021\n32 0.000862587068695575\n33 0.0008502048440277576\n34 0.0008379737846553326\n35 0.0008259259047918022\n36 0.0008140623685903847\n37 0.0008023850969038904\n38 0.0007908347761258483\n39 0.0007794745615683496\n40 0.0007682633586227894\n41 0.0007572302129119635\n42 0.0007463403744623065\n43 0.0007356303394772112\n44 0.0007250368944369256\n45 0.0007146321586333215\n46 0.0007043489022180438\n47 0.0006942375330254436\n48 0.0006842424627393484\n49 0.0006744143320247531\n50 0.0006647307309322059\n51 0.0006551811820827425\n52 0.0006457561394199729\n53 0.0006364858709275723\n54 0.0006273285835050046\n55 0.0006183229270391166\n56 0.0006094339769333601\n57 0.000600665807723999\n58 0.000592039548791945\n59 0.0005835291231051087\n60 0.0005751465796492994\n61 0.0005668827798217535\n62 0.0005587399355135858\n63 0.0005507126916199923\n64 0.0005427983123809099\n65 0.0005349876591935754\n66 0.0005272903363220394\n67 0.0005197130376473069\n68 0.0005122511647641659\n69 0.0005048967432230711\n70 0.0004976403433829546\n71 0.000490480859298259\n72 0.0004834288847632706\n73 0.0004764945770148188\n74 0.0004696374526247382\n75 0.0004628788447007537\n76 0.0004562275717034936\n77 0.00044968051952309906\n78 0.00044321140740066767\n79 0.0004368420341052115\n80 0.00043056640424765646\n81 0.0004243672883603722\n82 0.00041828094981610775\n83 0.00041226926259696484\n84 0.00040634092874825\n85 0.0004005084920208901\n86 0.0003947372897528112\n87 0.00038906928966753185\n88 0.000383479316951707\n89 0.00037796818651258945\n90 0.0003725424176082015\n91 0.0003671887388918549\n92 0.00036190811078995466\n93 0.0003566992236301303\n94 0.000351576047251001\n95 0.00034651753958314657\n96 0.0003415407845750451\n97 0.000336628349032253\n98 0.00033179065212607384\n99 0.00032702687894925475\n100 0.0003223252424504608\n101 0.00031769234919920564\n102 0.00031313669751398265\n103 0.00030863340361975133\n104 0.0003041986783500761\n105 0.0002998257987201214\n106 0.0002955195086542517\n107 0.00029126572189852595\n108 0.00028708367608487606\n109 0.00028295436641201377\n110 0.0002788918209262192\n111 0.0002748794504441321\n112 0.0002709267137106508\n113 0.00026703637558966875\n114 0.00026320572942495346\n115 0.00025941964122466743\n116 0.0002556926046963781\n117 0.0002520234265830368\n118 0.00024839406250976026\n119 0.0002448219747748226\n120 0.00024131007376126945\n121 0.00023783653159625828\n122 0.00023441844678018242\n123 0.00023104502179194242\n124 0.0002277280145790428\n125 0.0002244646311737597\n126 0.00022123432427179068\n127 0.00021804975403938442\n128 0.00021491637744475156\n129 0.00021182600175961852\n130 0.00020878782379440963\n131 0.00020578494877554476\n132 0.00020282616605982184\n133 0.0001999126689042896\n134 0.0001970435114344582\n135 0.00019420440366957337\n136 0.00019142168457619846\n137 0.00018866667232941836\n138 0.000185956567293033\n139 0.00018328377336729318\n140 0.00018065185577142984\n141 0.00017805679817683995\n142 0.00017549091717228293\n143 0.00017297384329140186\n144 0.0001704833412077278\n145 0.00016803611651994288\n146 0.0001656170643400401\n147 0.0001632404455449432\n148 0.000160889103426598\n149 0.0001585826394148171\n150 0.0001562982943141833\n151 0.0001540492958156392\n152 0.00015184165386017412\n153 0.00014965741138439626\n154 0.0001475059543736279\n155 0.00014538652612827718\n156 0.00014329359692055732\n157 0.00014123658183962107\n158 0.00013920401397626847\n159 0.00013720423157792538\n160 0.00013523211237043142\n161 0.00013328902423381805\n162 0.00013137134374119341\n163 0.00012948838411830366\n164 0.00012762623373419046\n165 0.0001257867261301726\n166 0.0001239851553691551\n167 0.00012219947529956698\n168 0.00012043984315823764\n169 0.00011871101742144674\n170 0.00011700631876010448\n171 0.0001153267512563616\n172 0.00011366987018845975\n173 0.00011203267058590427\n174 0.00011041987454518676\n175 0.0001088396820705384\n176 0.00010727271728683263\n177 0.00010573203326202929\n178 0.00010420992475701496\n179 0.00010271152132190764\n180 0.00010123683023266494\n181 9.978180605685338e-05\n182 9.834827505983412e-05\n183 9.693370520835742e-05\n184 9.554018470225856e-05\n185 9.417084220331162e-05\n186 9.28164372453466e-05\n187 9.148379467660561e-05\n188 9.016686817631125e-05\n189 8.887428703019395e-05\n190 8.759212505538017e-05\n191 8.633900142740458e-05\n192 8.509383769705892e-05\n193 8.387607522308826e-05\n194 8.266419899882749e-05\n195 8.14731974969618e-05\n196 8.03090661065653e-05\n197 7.915127207525074e-05\n198 7.801393076078966e-05\n199 7.689170888625085e-05\nw = : 2.0058376789093018\nb = : -0.013270352967083454\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    y_pre = model(x_data)\n",
    "    loss = criterion(y_pre, y_data)  # 这里的loss是一个标量，这里的loss是一个对象，他会自动调用__str__(), 所以不会产生计算图，是安全的。\n",
    "    print(epoch, loss.data.item())\n",
    "\n",
    "    optimizer.zero_grad()  # 梯度归零\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 进行更新，根据所有参数的梯度与设置的学习率\n",
    "\n",
    "print(\"w = :\", model.linear.weight.item())\n",
    "print(\"b = :\", model.linear.bias.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y_pred: tensor([[8.0101]])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print(\"y_pred:\", y_test.data)"
   ]
  },
  {
   "source": [
    "可变参数方式传参与对象可调用简单介绍："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello2 {'x': 4, 'y': 5}\n"
     ]
    }
   ],
   "source": [
    "class FooBar(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print(\"Hello\" + str(args[1]), kwargs)\n",
    "\n",
    "\n",
    "foo = FooBar()\n",
    "foo(1, 2, 3, x=4, y=5) # 可变参数方式传参与对象可调用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}