{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GoogleNet\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"../dataset/\", train=True, download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root=\"../dataset/\", train=False, download=True, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class InceptionA(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        output = [branch1x1, branch5x5, branch3x3, branch_pool]\n",
    "\n",
    "        return torch.cat(output, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(88, 20, kernel_size=5)\n",
    "\n",
    "        self.inception1 = InceptionA(in_channels=10)\n",
    "        self.inception2 = InceptionA(in_channels=20)\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(1408, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.maxpool(self.conv1(x)))\n",
    "        x = self.inception1(x)\n",
    "        x = F.relu(self.maxpool(self.conv2(x)))\n",
    "        x = self.inception2(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "device = torch.device((\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_dataloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 300 == 299:\n",
    "            print(\"[%d, %5d] loss: %.3f\" %(epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test():\n",
    "    correct = .0\n",
    "    total = .0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return (correct/total)*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 1.811\n",
      "[1,   600] loss: 0.416\n",
      "[1,   900] loss: 0.280\n",
      "[1,  1200] loss: 0.226\n",
      "[1,  1500] loss: 0.181\n",
      "[1,  1800] loss: 0.163\n",
      "[1,  2100] loss: 0.150\n",
      "[1,  2400] loss: 0.161\n",
      "[1,  2700] loss: 0.126\n",
      "[1,  3000] loss: 0.112\n",
      "[1,  3300] loss: 0.113\n",
      "[1,  3600] loss: 0.110\n",
      "[1,  3900] loss: 0.105\n",
      "[1,  4200] loss: 0.113\n",
      "[1,  4500] loss: 0.120\n",
      "[1,  4800] loss: 0.102\n",
      "[1,  5100] loss: 0.088\n",
      "[1,  5400] loss: 0.094\n",
      "[1,  5700] loss: 0.095\n",
      "[1,  6000] loss: 0.072\n",
      "[1,  6300] loss: 0.103\n",
      "[1,  6600] loss: 0.085\n",
      "[1,  6900] loss: 0.096\n",
      "[1,  7200] loss: 0.084\n",
      "[1,  7500] loss: 0.078\n",
      "accuracy on test set: 97%\n",
      "[2,   300] loss: 0.066\n",
      "[2,   600] loss: 0.081\n",
      "[2,   900] loss: 0.075\n",
      "[2,  1200] loss: 0.082\n",
      "[2,  1500] loss: 0.064\n",
      "[2,  1800] loss: 0.072\n",
      "[2,  2100] loss: 0.071\n",
      "[2,  2400] loss: 0.066\n",
      "[2,  2700] loss: 0.062\n",
      "[2,  3000] loss: 0.079\n",
      "[2,  3300] loss: 0.062\n",
      "[2,  3600] loss: 0.078\n",
      "[2,  3900] loss: 0.075\n",
      "[2,  4200] loss: 0.054\n",
      "[2,  4500] loss: 0.061\n",
      "[2,  4800] loss: 0.071\n",
      "[2,  5100] loss: 0.056\n",
      "[2,  5400] loss: 0.063\n",
      "[2,  5700] loss: 0.063\n",
      "[2,  6000] loss: 0.059\n",
      "[2,  6300] loss: 0.068\n",
      "[2,  6600] loss: 0.071\n",
      "[2,  6900] loss: 0.054\n",
      "[2,  7200] loss: 0.059\n",
      "[2,  7500] loss: 0.061\n",
      "accuracy on test set: 97%\n",
      "[3,   300] loss: 0.048\n",
      "[3,   600] loss: 0.061\n",
      "[3,   900] loss: 0.059\n",
      "[3,  1200] loss: 0.035\n",
      "[3,  1500] loss: 0.045\n",
      "[3,  1800] loss: 0.054\n",
      "[3,  2100] loss: 0.065\n",
      "[3,  2400] loss: 0.062\n",
      "[3,  2700] loss: 0.055\n",
      "[3,  3000] loss: 0.049\n",
      "[3,  3300] loss: 0.052\n",
      "[3,  3600] loss: 0.039\n",
      "[3,  3900] loss: 0.048\n",
      "[3,  4200] loss: 0.053\n",
      "[3,  4500] loss: 0.061\n",
      "[3,  4800] loss: 0.047\n",
      "[3,  5100] loss: 0.046\n",
      "[3,  5400] loss: 0.057\n",
      "[3,  5700] loss: 0.053\n",
      "[3,  6000] loss: 0.049\n",
      "[3,  6300] loss: 0.046\n",
      "[3,  6600] loss: 0.059\n",
      "[3,  6900] loss: 0.048\n",
      "[3,  7200] loss: 0.047\n",
      "[3,  7500] loss: 0.042\n",
      "accuracy on test set: 98%\n",
      "[4,   300] loss: 0.041\n",
      "[4,   600] loss: 0.047\n",
      "[4,   900] loss: 0.044\n",
      "[4,  1200] loss: 0.049\n",
      "[4,  1500] loss: 0.027\n",
      "[4,  1800] loss: 0.040\n",
      "[4,  2100] loss: 0.049\n",
      "[4,  2400] loss: 0.037\n",
      "[4,  2700] loss: 0.046\n",
      "[4,  3000] loss: 0.046\n",
      "[4,  3300] loss: 0.064\n",
      "[4,  3600] loss: 0.037\n",
      "[4,  3900] loss: 0.049\n",
      "[4,  4200] loss: 0.042\n",
      "[4,  4500] loss: 0.050\n",
      "[4,  4800] loss: 0.039\n",
      "[4,  5100] loss: 0.037\n",
      "[4,  5400] loss: 0.048\n",
      "[4,  5700] loss: 0.037\n",
      "[4,  6000] loss: 0.050\n",
      "[4,  6300] loss: 0.041\n",
      "[4,  6600] loss: 0.046\n",
      "[4,  6900] loss: 0.029\n",
      "[4,  7200] loss: 0.050\n",
      "[4,  7500] loss: 0.034\n",
      "accuracy on test set: 98%\n",
      "[5,   300] loss: 0.052\n",
      "[5,   600] loss: 0.032\n",
      "[5,   900] loss: 0.035\n",
      "[5,  1200] loss: 0.050\n",
      "[5,  1500] loss: 0.035\n",
      "[5,  1800] loss: 0.043\n",
      "[5,  2100] loss: 0.033\n",
      "[5,  2400] loss: 0.043\n",
      "[5,  2700] loss: 0.026\n",
      "[5,  3000] loss: 0.033\n",
      "[5,  3300] loss: 0.037\n",
      "[5,  3600] loss: 0.036\n",
      "[5,  3900] loss: 0.031\n",
      "[5,  4200] loss: 0.036\n",
      "[5,  4500] loss: 0.036\n",
      "[5,  4800] loss: 0.040\n",
      "[5,  5100] loss: 0.030\n",
      "[5,  5400] loss: 0.031\n",
      "[5,  5700] loss: 0.047\n",
      "[5,  6000] loss: 0.049\n",
      "[5,  6300] loss: 0.034\n",
      "[5,  6600] loss: 0.032\n",
      "[5,  6900] loss: 0.052\n",
      "[5,  7200] loss: 0.038\n",
      "[5,  7500] loss: 0.030\n",
      "accuracy on test set: 98%\n",
      "[6,   300] loss: 0.028\n",
      "[6,   600] loss: 0.035\n",
      "[6,   900] loss: 0.036\n",
      "[6,  1200] loss: 0.020\n",
      "[6,  1500] loss: 0.026\n",
      "[6,  1800] loss: 0.038\n",
      "[6,  2100] loss: 0.039\n",
      "[6,  2400] loss: 0.033\n",
      "[6,  2700] loss: 0.043\n",
      "[6,  3000] loss: 0.036\n",
      "[6,  3300] loss: 0.036\n",
      "[6,  3600] loss: 0.027\n",
      "[6,  3900] loss: 0.030\n",
      "[6,  4200] loss: 0.032\n",
      "[6,  4500] loss: 0.037\n",
      "[6,  4800] loss: 0.032\n",
      "[6,  5100] loss: 0.033\n",
      "[6,  5400] loss: 0.036\n",
      "[6,  5700] loss: 0.038\n",
      "[6,  6000] loss: 0.034\n",
      "[6,  6300] loss: 0.049\n",
      "[6,  6600] loss: 0.030\n",
      "[6,  6900] loss: 0.021\n",
      "[6,  7200] loss: 0.036\n",
      "[6,  7500] loss: 0.044\n",
      "accuracy on test set: 98%\n",
      "[7,   300] loss: 0.025\n",
      "[7,   600] loss: 0.027\n",
      "[7,   900] loss: 0.026\n",
      "[7,  1200] loss: 0.025\n",
      "[7,  1500] loss: 0.036\n",
      "[7,  1800] loss: 0.032\n",
      "[7,  2100] loss: 0.032\n",
      "[7,  2400] loss: 0.026\n",
      "[7,  2700] loss: 0.023\n",
      "[7,  3000] loss: 0.025\n",
      "[7,  3300] loss: 0.037\n",
      "[7,  3600] loss: 0.019\n",
      "[7,  3900] loss: 0.029\n",
      "[7,  4200] loss: 0.021\n",
      "[7,  4500] loss: 0.036\n",
      "[7,  4800] loss: 0.030\n",
      "[7,  5100] loss: 0.022\n",
      "[7,  5400] loss: 0.029\n",
      "[7,  5700] loss: 0.026\n",
      "[7,  6000] loss: 0.043\n",
      "[7,  6300] loss: 0.027\n",
      "[7,  6600] loss: 0.029\n",
      "[7,  6900] loss: 0.027\n",
      "[7,  7200] loss: 0.025\n",
      "[7,  7500] loss: 0.034\n",
      "accuracy on test set: 98%\n",
      "[8,   300] loss: 0.022\n",
      "[8,   600] loss: 0.018\n",
      "[8,   900] loss: 0.023\n",
      "[8,  1200] loss: 0.026\n",
      "[8,  1500] loss: 0.029\n",
      "[8,  1800] loss: 0.031\n",
      "[8,  2100] loss: 0.026\n",
      "[8,  2400] loss: 0.025\n",
      "[8,  2700] loss: 0.025\n",
      "[8,  3000] loss: 0.024\n",
      "[8,  3300] loss: 0.028\n",
      "[8,  3600] loss: 0.032\n",
      "[8,  3900] loss: 0.029\n",
      "[8,  4200] loss: 0.027\n",
      "[8,  4500] loss: 0.019\n",
      "[8,  4800] loss: 0.017\n",
      "[8,  5100] loss: 0.030\n",
      "[8,  5400] loss: 0.028\n",
      "[8,  5700] loss: 0.020\n",
      "[8,  6000] loss: 0.020\n",
      "[8,  6300] loss: 0.023\n",
      "[8,  6600] loss: 0.023\n",
      "[8,  6900] loss: 0.036\n",
      "[8,  7200] loss: 0.022\n",
      "[8,  7500] loss: 0.035\n",
      "accuracy on test set: 98%\n",
      "[9,   300] loss: 0.016\n",
      "[9,   600] loss: 0.022\n",
      "[9,   900] loss: 0.020\n",
      "[9,  1200] loss: 0.022\n",
      "[9,  1500] loss: 0.033\n",
      "[9,  1800] loss: 0.015\n",
      "[9,  2100] loss: 0.023\n",
      "[9,  2400] loss: 0.015\n",
      "[9,  2700] loss: 0.021\n",
      "[9,  3000] loss: 0.022\n",
      "[9,  3300] loss: 0.027\n",
      "[9,  3600] loss: 0.046\n",
      "[9,  3900] loss: 0.023\n",
      "[9,  4200] loss: 0.028\n",
      "[9,  4500] loss: 0.022\n",
      "[9,  4800] loss: 0.025\n",
      "[9,  5100] loss: 0.035\n",
      "[9,  5400] loss: 0.030\n",
      "[9,  5700] loss: 0.023\n",
      "[9,  6000] loss: 0.020\n",
      "[9,  6300] loss: 0.023\n",
      "[9,  6600] loss: 0.022\n",
      "[9,  6900] loss: 0.020\n",
      "[9,  7200] loss: 0.027\n",
      "[9,  7500] loss: 0.022\n",
      "accuracy on test set: 99%\n",
      "[10,   300] loss: 0.015\n",
      "[10,   600] loss: 0.009\n",
      "[10,   900] loss: 0.024\n",
      "[10,  1200] loss: 0.024\n",
      "[10,  1500] loss: 0.014\n",
      "[10,  1800] loss: 0.019\n",
      "[10,  2100] loss: 0.020\n",
      "[10,  2400] loss: 0.025\n",
      "[10,  2700] loss: 0.021\n",
      "[10,  3000] loss: 0.025\n",
      "[10,  3300] loss: 0.016\n",
      "[10,  3600] loss: 0.024\n",
      "[10,  3900] loss: 0.021\n",
      "[10,  4200] loss: 0.017\n",
      "[10,  4500] loss: 0.017\n",
      "[10,  4800] loss: 0.030\n",
      "[10,  5100] loss: 0.031\n",
      "[10,  5400] loss: 0.016\n",
      "[10,  5700] loss: 0.030\n",
      "[10,  6000] loss: 0.025\n",
      "[10,  6300] loss: 0.031\n",
      "[10,  6600] loss: 0.029\n",
      "[10,  6900] loss: 0.036\n",
      "[10,  7200] loss: 0.020\n",
      "[10,  7500] loss: 0.016\n",
      "accuracy on test set: 98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    epoch_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        epoch_list.append(epoch)\n",
    "        acc_list.append(acc)\n",
    "        print(\"accuracy on test set: %.4d%%\" %acc)\n",
    "\n",
    "\n",
    "    plt.plot(epoch_list, acc_list)\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# ResNet\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.channels = in_channels\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "        return F.relu(x + y)    # 注意: 先求和再激活"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5) # 88 = 24x3 + 16\n",
    "\n",
    "        self.rblock1 = ResidualBlock(16)\n",
    "        self.rblock2 = ResidualBlock(32)\n",
    "\n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(512, 10) # 暂时不知道1408咋能自动出来的\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "\n",
    "        x = self.mp(F.relu(self.conv1(x)))\n",
    "        x = self.rblock1(x)\n",
    "        x = self.mp(F.relu(self.conv2(x)))\n",
    "        x = self.rblock2(x)\n",
    "\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "model = ResNet().to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_dataloader, 0):\n",
    "        inputs, target = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return (100*correct/total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.030\n",
      "[1,   600] loss: 0.021\n",
      "[1,   900] loss: 0.037\n",
      "[1,  1200] loss: 0.049\n",
      "[1,  1500] loss: 0.038\n",
      "[1,  1800] loss: 0.033\n",
      "[1,  2100] loss: 0.037\n",
      "[1,  2400] loss: 0.042\n",
      "[1,  2700] loss: 0.041\n",
      "[1,  3000] loss: 0.041\n",
      "[1,  3300] loss: 0.030\n",
      "[1,  3600] loss: 0.031\n",
      "[1,  3900] loss: 0.024\n",
      "[1,  4200] loss: 0.034\n",
      "[1,  4500] loss: 0.035\n",
      "[1,  4800] loss: 0.037\n",
      "[1,  5100] loss: 0.033\n",
      "[1,  5400] loss: 0.031\n",
      "[1,  5700] loss: 0.030\n",
      "[1,  6000] loss: 0.042\n",
      "[1,  6300] loss: 0.027\n",
      "[1,  6600] loss: 0.050\n",
      "[1,  6900] loss: 0.030\n",
      "[1,  7200] loss: 0.033\n",
      "[1,  7500] loss: 0.033\n",
      "accuracy on test set: 0098%\n",
      "[2,   300] loss: 0.027\n",
      "[2,   600] loss: 0.031\n",
      "[2,   900] loss: 0.027\n",
      "[2,  1200] loss: 0.034\n",
      "[2,  1500] loss: 0.022\n",
      "[2,  1800] loss: 0.023\n",
      "[2,  2100] loss: 0.022\n",
      "[2,  2400] loss: 0.028\n",
      "[2,  2700] loss: 0.026\n",
      "[2,  3000] loss: 0.024\n",
      "[2,  3300] loss: 0.024\n",
      "[2,  3600] loss: 0.021\n",
      "[2,  3900] loss: 0.026\n",
      "[2,  4200] loss: 0.024\n",
      "[2,  4500] loss: 0.035\n",
      "[2,  4800] loss: 0.017\n",
      "[2,  5100] loss: 0.037\n",
      "[2,  5400] loss: 0.015\n",
      "[2,  5700] loss: 0.034\n",
      "[2,  6000] loss: 0.023\n",
      "[2,  6300] loss: 0.024\n",
      "[2,  6600] loss: 0.030\n",
      "[2,  6900] loss: 0.028\n",
      "[2,  7200] loss: 0.034\n",
      "[2,  7500] loss: 0.038\n",
      "accuracy on test set: 0099%\n",
      "[3,   300] loss: 0.016\n",
      "[3,   600] loss: 0.014\n",
      "[3,   900] loss: 0.018\n",
      "[3,  1200] loss: 0.024\n",
      "[3,  1500] loss: 0.011\n",
      "[3,  1800] loss: 0.025\n",
      "[3,  2100] loss: 0.017\n",
      "[3,  2400] loss: 0.031\n",
      "[3,  2700] loss: 0.023\n",
      "[3,  3000] loss: 0.022\n",
      "[3,  3300] loss: 0.022\n",
      "[3,  3600] loss: 0.026\n",
      "[3,  3900] loss: 0.023\n",
      "[3,  4200] loss: 0.023\n",
      "[3,  4500] loss: 0.010\n",
      "[3,  4800] loss: 0.014\n",
      "[3,  5100] loss: 0.024\n",
      "[3,  5400] loss: 0.020\n",
      "[3,  5700] loss: 0.029\n",
      "[3,  6000] loss: 0.013\n",
      "[3,  6300] loss: 0.020\n",
      "[3,  6600] loss: 0.020\n",
      "[3,  6900] loss: 0.029\n",
      "[3,  7200] loss: 0.023\n",
      "[3,  7500] loss: 0.033\n",
      "accuracy on test set: 0099%\n",
      "[4,   300] loss: 0.008\n",
      "[4,   600] loss: 0.016\n",
      "[4,   900] loss: 0.018\n",
      "[4,  1200] loss: 0.015\n",
      "[4,  1500] loss: 0.020\n",
      "[4,  1800] loss: 0.014\n",
      "[4,  2100] loss: 0.015\n",
      "[4,  2400] loss: 0.022\n",
      "[4,  2700] loss: 0.016\n",
      "[4,  3000] loss: 0.018\n",
      "[4,  3300] loss: 0.013\n",
      "[4,  3600] loss: 0.013\n",
      "[4,  3900] loss: 0.024\n",
      "[4,  4200] loss: 0.011\n",
      "[4,  4500] loss: 0.017\n",
      "[4,  4800] loss: 0.027\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-81-e7780b412048>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m         \u001B[0macc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mepoch_list\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-80-35c0aa13049a>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\minhu\\miniconda3\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 245\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\minhu\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 145\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    epoch_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        epoch_list.append(epoch)\n",
    "        acc_list.append(acc)\n",
    "        print(\"accuracy on test set: %.d%%\" %acc)\n",
    "\n",
    "\n",
    "    plt.plot(epoch_list, acc_list)\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}